{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1주차 과제",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOrQzNIhvtk1O3lDh73a77K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/da-in/ai_school_precourse/blob/master/1%EC%A3%BC%EC%B0%A8_%EA%B3%BC%EC%A0%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgOzQHs1UCKW",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82dcAC8PqNuF",
        "colab_type": "text"
      },
      "source": [
        "#**(인공지능 사관학교 프리코스 과제 목차)**\n",
        "##1주차 과제 (2020.06.11)\n",
        ">언어, 음성, 이미지, 자율주행 분야의 다양한 제품과 서비스 속 인공지능 기술들 분석하기.\n",
        "---\n",
        "###1. 언어\n",
        "챗봇처럼 인공지능(AI, Artificial Intelligence) 분야에서 사람 언어를 학습시키려는 노력은 계속되고 있습니다. \n",
        "\n",
        "**자연어 처리**\n",
        ">인공지능이 사람 언어를 이해하기 위해서는 자연어 처리(natural language processing) 과정을 거쳐야 합니다. 자연어 처리란, 인간이 발화하는 언어 현상을 기계적으로 분석해 컴퓨터가 이해할 수 있는 형태로 만드는 것입니다.\n",
        "\n",
        ">자연어 처리를 진행하면 글의 감정을 분석할 수 있습니다. 감정을 판단하기 위해 긍정, 부정 문장을 모아 데이터를 만든 후, 인공지능에게 각 문장의 긍정, 부정 속성을 학습시킵니다. 인공지능은 학습 과정에서 각 단어의 노출 빈도를 바탕으로 데이터 외의 새로운 문장을 평가할 수 있습니다.\n",
        "\n",
        ">예를 들어 “나는 기분이 안 좋아”라는 문장에 ‘부정’이라는 이름을 붙여줍니다. 그러면 인공지능은 인간처럼 이해하는 것이 아니라 문장을 분해합니다. ‘나는’, ’기분이’, ’안 좋아’로 분해하고, 각 단어의 노출 빈도를 집계합니다. 여러 문장을 학습하면서 ’안’이라는 단어가 있으면 부정 감정이라는 것을 학습하게 됩니다. 이를 바탕으로 새로운 문장, “컨디션이 안 좋다”에 대해 부정 감정을 나타내고 있다고 판단할 수 있습니다.\n",
        "출처 : 삼성SDS 커뮤니케이션팀 | SDS 스토리\n",
        "\n",
        "**AI 번역기(MS, Google, Naver)**\n",
        ">AI(Artificial Intelligence, 인공지능) 기술을 품은 번역기는 이전보다 훨씬 섬세하고 유연해졌습니다. \n",
        "\n",
        ">마이크로소프트(이하, MS)는 지난해 11월, 처음으로 인공지능 신경망(ANN, Artificial Neural Network) 기반 번역 서비스를 공개했습니다. 인공 신경망은 인간의 두뇌와 비슷한 방식으로 여러 가지 정보를 처리하는 *알고리즘을 말하는데요. 당시 MS는 영어, 독일어, 아랍어, 중국어를 포함한 10가지 언어를 지원했고, 이번에 한국어를 추가하면서 총 11가지 언어에 최대 10,000자까지 번역하게 됐습니다.\n",
        "신경망 기반 번역은 문장 전체의 맥락을 파악해 사람이 말하는 것처럼 자연스러운 번역이 특징입니다.\n",
        "\n",
        ">구글도 지난 11월, 한국어를 포함한 8개의 언어조합에 ‘구글 신경망 기계번역 기술 ‘GNMT(Google Neural Machine Translation)’를 적용한 번역기를 선보였습니다. 구체적으로 어떤 변화가 있는지 구글 한국 블로그에 실린 내용을 참고해 비교해봤습니다.\n",
        "\n",
        ">국내 번역 서비스인 네이버 파파고(Papago)는 베타 서비스 출시 후, 약 1년 만에 인공신경망 번역 기술 ‘N2MT(Naver Neural Machine Translation)’가 적용된 정식 서비스를 선보였는데요. 이전과 크게 달라진 점은 해당 기술이 적용되는 글자 수 범위가 200자에서 최대 5,000자까지 확대된 것입니다. 장문을 잘라 쓸 수밖에 없었던 과거와 달리, 신문기사나 논문처럼 긴 문장도 한 번에 정확하고 자연스러운 번역 결과를 얻을 수 있게 되었습니다.\n",
        "\n",
        ">출처 : https://iropke.com/archive/artificial-translator.html\n",
        "\n",
        "---\n",
        "###2. 음성\n",
        "\n",
        "요즘 스마트폰은 대부분 음성 인식 서비스가 탑재되어 있습니다. 애플은 시리(siri), 삼성은 빅스비(Bixby), 구글은 구글 어시스턴트(Google Assistant) 등을 내세우고 있습니다. 이들은 단순히 음성을 인식하여 특정 행위를 하는 수준을 넘어 인공지능(AI)을 기반으로 작동하는 것으로 그 성능을 해마다 향상시켜 나가고 있습니다.\n",
        "\n",
        "**음성 인식 기술**\n",
        ">음성 인식 기술이란, 사람이 말하는 음성 언어를 컴퓨터가 해석하여 그 내용을 **문자 데이터**로 전환하는 처리를 말합니다. 즉, 사람이 특정 명령을 입력하거나 아이콘을 클릭하는 행위 없이 오로지 음성으로 데이터를 처리할 수 있게 된 것입니다.\n",
        ">사실, 음성 인식에 대한 연구는 1950년대부터 시작되었습니다. 초기에는 숫자, 음절, 모음 등을 인식하는 시스템을 만들기 시작하였고, 고립 단어(Isolated Word) 인식에서 연결 단어(Connected word)를 인식하는 시스템이 개발되었습니다. 최근에 들어서야 딥러닝, 머신 러닝과 같은 AI 기술이 활용되면서 음성 인식 오류가 낮아졌고, 본격적으로 상용화가 이루어졌습니다. 음성 인식 기술은 시장 조사 기관인 트랜드포스에 따르면 16년 26억 달러에서 21년에는 160억 달러의 규모로 시장이 확산될 것이라고 추산하고 있을 정도로 중요한 기술 중 하나로 자리매김하였습니다. \n",
        "\n",
        ">[출처] 음성 인식 기술의 적용 사례|작성자 슈어소프트테크\n",
        "\n",
        "**음성 인식과 딥러닝**\n",
        ">이러한 음성인식기술이 최근 비약적으로 발전한 배경엔 ‘딥러닝(deep learning) 기술’이 있다. 딥러닝 기술이란 사물이나 데이터를 군집화하거나 분류하는 데 사용하는 기술로, 많은 데이터를 컴퓨터에 입력하고 비슷한 것끼리 분류하도록 하는 ‘기계 학습’ 알고리즘 중 하나다.\n",
        "\n",
        ">기계학습 알고리즘으로는 과거에도 ‘의사결정나무’, ‘베이지안망’, ‘서포트벡터머신(SVM)’, ‘인공신경망’이 있었다. 하지만 기존의 인공신경망 기술은 사람의 실제 신경망을 구현하는 데에 있어 복잡성과 규모에 한계가 있었다. 반면 딥러닝 기술은 얕고 단순한 기존 인공신경망의 한계를 극복하고 보완한 ‘심층 신경망’ 기계 학습 알고리즘이다. 이 딥러닝 알고리즘은 음성 데이터의 입력, 각 모델들의 특징벡터 추출, 출력까지 복잡한 ‘맵핑(mapping)’ 과정이 이전보다 훨씬 빠르고 정확하도록 만들어준다.\n",
        "\n",
        ">딥러닝 기술이 최근부터 급격히 발전된 배경으론 크게 컴퓨터 하드웨어의 발전과 빅데이터 시대의 도래가 꼽힌다. 박천덕 교수(한림대 CVPR연구실)는 “신경망이 크고 복잡해질수록 많은 데이터가 필요한데, 과거엔 데이터가 부족하고 이를 처리할 컴퓨터 성능도 좋지 못했다”며 “지금은 빅데이터 시대로 데이터가 양적으로 많아졌고, 이런 방대한 양의 데이터를 처리할 CPU, GPU와 같은 하드웨어도 크게 발전했다”고 설명했다.\n",
        "\n",
        ">음성신호와 같은 연속적인 데이터를 모델링하는 방법으론 전통적으로 HMM(Hidden Marcov Model, 은닉마르코프 모델)이 있었다. HMM은 음성신호의 변동을 확률 변수로 취급해 주어진 음성의 문자열을 찾아낸다. 하지만 이는 확률에 기반하므로 예외가 많이 발생한다는 단점이 있다. 그 돌파구로 현재의 음성인식기술은 정확성이 높은 딥러닝 기술과 HMM 기술을 함께 활용하고 있다. 딥러닝 기술은 HMM으로 대상을 만들어 학습하고 딥러닝으로 모델링하는 방법을 이용한다. 한국전자통신연구원(ETRI) 음성지능연구팀 김동현 연구원은 “최근에는 HMM 없이 모델링 하려는 시도도 있지만 일반적으로 HMM을 이용해 구분한 트라이폰(triphone, 3음소열) 모델들을 딥러닝에 구별대상으로 놓고 딥러닝 모델을 만들어 이용한다”고 말했다.\n",
        "\n",
        ">출처 : 고대신문(http://www.kunews.ac.kr)\n",
        "\n",
        "**애플 사 시리(Siri)**\n",
        ">2011년 애플은 음성 기반 개인비서 서비스인 ‘시리(Siri)’를 출시했다. 시리를 필두로 2016년 구글의 ‘구글 홈’, 마이크로소프트(MS)의 ‘인보크’, 국내기업 KT의 ‘기가지니’, SK텔레콤의 ‘누구’ 등 국내외 음성기반 서비스들이 쏟아지고 있다. 음성 서비스 관련 산업은 음성인식기술의 급격한 발전에 따라 꾸준한 성장세를 보이고 있다. 시장조사업체 가트너는 2015년 3억6000만 달러(약 4050억 원)였던 글로벌 음성인식 스피커 시장 규모가 연평균 40% 이상 성장해 2020년엔 21억 달러(약 2조3600억 원) 수준에 이를 것으로 전망했다. 이렇게 빠르게 발전하는 음성인식기술엔 어떤 원리가 적용되고, 음성인식기는 어떻게 작동할까.\n",
        "\n",
        ">출처 : 고대신문(http://www.kunews.ac.kr)\n",
        "\n",
        "---\n",
        "###3. 이미지\n",
        "\n",
        "**구글 포토(Google Photo) 서비스**\n",
        "\n",
        ">이미지 인식 기술은 이미 우리 생활 가까이에서 많이 사용되고 있습니다. 스마트폰으로 사진 촬영을 자주 하시는 분이라면 구글 포토 서비스에 사진을 백업해두고 있을 텐데요. 서비스 이용을 안 하신 다면 지금이라도 신청하시길 권해드립니다. 고화질 원본 이미지가 아니라면 무제한 저장 용량을 제공하거든요. 그리고, 거기에 덧붙여 구글 포토는 놀라운 분류와 검색 기능을 가지고 있습니다.\n",
        "\n",
        ">어떤 지역에서 찍은 사진을 찾고 싶거나, 특정 인물을 검색하고 싶다면 구글 포토가 알아서 만들어 놓은 사진첩을 통해 관련 사진을 찾을 수 있습니다. 심지어 강아지가 등장하는 사진, 우산을 들고 찍은 사진을 찾고 싶다면 검색어로 ‘강아지’, ‘우산’ 등을 입력해보세요! 짜잔~ 여러분이 저장한 사진 중에서 해당 이미지가 포함된 사진을 검색해 결과로 보여줍니다.\n",
        "\n",
        "**이미지 분석을 통해 질병을 예측하고 분석하는 의료 서비스**\n",
        "\n",
        ">우리나라 성인 남녀 사망률 상위를 차지하는 질병, 폐암은 말기에 발견되는 경우 생존율 6.1%지만 조기 발견의 경우 생존율이 64%까지 상승한다고 합니다. 그런데 국내 폐암 환자 조기진단 비율은 20.7%에 불과한데요. 병변의 크기가 작거나 다른 장기에 가려져 판독하기 어려운 경우 X-선 검사에서 폐암을 놓치기 쉬워서 그렇습니다.\n",
        "\n",
        ">국내 의료 스타트업에서는 이런 문제점들을 개선하는 이미지 분석 서비스를 내놓고 있습니다. CT검사 결과를 기반으로 학습한 이미지 분석 엔진이 폐 결절을 97% 정확도로 찾아내고, 또 영상 판독을 보조해주는 경우 의사의 판독 정확도는 20%가 향상되는 실험 결과를 내놨습니다.\n",
        "\n",
        ">폐암뿐만 아니라 유방암이나 조직 검사, 그리고 다른 질병에도 활용 범위를 넓혀가고 있고 국내 주요 대학병원에서 이미 활용 중이라고 합니다.\n",
        "\n",
        "> 출처 : 삼성SDS 커뮤니케이션팀 | SDS 스토리 https://www.samsungsds.com/global/ko/news/story/visual-0214.html\n",
        "\n",
        "**(연속된 이미지)엔비디아사의 인공지능 CCTV**\n",
        ">인공지능(AI) 보안 분야의 활용된 사례는 한화 테크윈과 엔비디아사의 인공지능 CCTV이다.\n",
        "\n",
        ">동영상을 실시간 분석하고 다양한 사례를 스스로 학습하는 능력까지 보유한 AI이다. 더욱더 놀라운 사실은 평소와 다른 상황을 촬영하게 될 경우 스스로 인식하여 경찰에 이상신호 송출까지 하는 기능이 있다고 한다. 이렇게 인공지능(AI)를 활용한 보안 분야에 CCTV가 확장된다면 범죄율은 확실히 줄어들 것이라고 생각이 든다.\n",
        "\n",
        ">출처 : 네이버 블로그 (SD아카데미) https://m.blog.naver.com/sundooedu/221192593618\n",
        "\n",
        "---\n",
        "\n",
        "###4. 자율주행 : \n",
        "\n",
        ">자율주행은 운전자 개입 없이 자동차가 스스로 도로 환경을 인식하고 조항, 변속 장치 등을 제어하여 목적지까지 주행하는 것을 가리킵니다.\n",
        "\n",
        "**미국 자동차기술자협회(SAE) 자율주행 발전 5단계**\n",
        ">미국 자동차기술자협회(SAE)는 자율주행 발전을 5단계로 제시했습니다. 0단계는 자율주행 기술이 없는 상태, 1,2단계는 운전자를 지원하거나 하나 이상의 자동화 기능이 포함된 단계입니다. 3단계는 특정 상황 시 운전자 개입이 필요한 조건부 자동화 단게입니다. 4,5단계는 모두 고도로 혹은 완전 자동화되어 운전자 개입이 필요없는 단계이며 특히 5단계의 경우 운전자가 탑승하지 않아도 모든 환경에서 자율주행이 가능합니다.\n",
        "\n",
        "**자율주행 자동차의 구조**\n",
        ">자율주행 자동차의 구조는 크게 센서, 프로세서, 알고리즘, 액추에이터로 구성됩니다. 센서가 데이터를 수집하면 프로세서가 그 데이터를 처리합니다. 그러면 알고리즘이 처리 결과를 해석, 주행 경로 등 운행에 대해 결정을 내리고 액추에이터가 운행에 필요한 시스템을 제어하는 것이죠. 자율주행이 기본적으로 운전자 판단 능력을 대체하는 것임을 생각할 때 구조의 핵심은 인공지능시스템인 알고리즘이라고 할 수 있겠습니다.\n",
        "\n",
        ">자세히 말하자면 자율주행 알고리즘은 라이다, 레이더, 센서, 카메라 등의 장치로부터 입력된 주변 상황 정보 및 운전자의 상태 등을 분석하여 가속, 브레이크 작동, 차선 유지 등을 액추에이터가 수행하게끔 하는 것입니다. 인간이 학습과 경험을 통해 무언가를 습득하듯이 알고리즘을 통해 자율주행이 실현되기 위해서는 엄청난 양의 기계 학습, 즉 딥러닝이 필수적입니다. 구글의 경우 2017년 말 기준으로 약 643만km 이상의 도로 주행을 통해 기계 학습을 위한 빅 데이터를 확보했다고 합니다. \n",
        "\n",
        "**현대 제네시스 G80기반 자율주행차**\n",
        "\n",
        ">지난 2월 2일, 현대자동차가 수소전기차 제네시스 G80기반 자율주행차로 서울-평창간 고속도로 약 190km 자율주행에 성공했습니다. 세계 최초로 수소전기차를 이용해 자율주행 기술을 선보인 사례입니다.\n",
        "\n",
        ">먼저 정밀지도에 대해 설명해드리겠습니다. 자율주행 실현을 위해 꼭 필요한 것이 정밀지도입니다. 자율주행 시 주변 상황을 인식하는 역할을 하는 센서는 물리적 한계를 가질 수 밖에 없는데요. 정밀지도 정보가 이 한계를 보완하고 센서가 연산해야 하는 영역을 최소한으로 축소하여 센서의 성능 향상에도 기여하기 때문입니다.\n",
        "\n",
        ">현대엠엔소프트는 2011년부터 정밀지도 개발에 본격적으로 나섰고, 2015년 전국 2차선 이상 주요 도로에 대한 ADAS(첨단 운전자 보조 시스템) 지도 구축을 완료했으며 2017년 1월 세계 최초로 4단계 야간 자율주행까지 마친 바 있습니다. 실제 자율주행을 도와주는 정밀지도 개발이 가능한 수준까지 도달했다고 합니다.\n",
        "\n",
        ">현대엠엔소프트의 ADAS 지도는 모바일 내비게이션 애플리케이션 ‘올 뉴 맵피’에도 적용되어 있고, 제네시스 EQ900과 아이오닉, 기아차 신형 K9 차량에도 적용되어 있습니다. 특히 K9의 경우 ADAS 지도를 기반으로 한 반자율기능 ‘내비게이션 기반 스마트 크루즈 컨트롤’을 갖추고 있습니다.\n",
        "\n",
        ">자료 출처: https://blog.hyundai-mnsoft.com/1444 [현대엠엔소프트 공식 기업 블로그]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tDWZ6j2pb6S",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}